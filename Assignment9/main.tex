%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Welcome to Overleaf --- just edit your LaTeX on the left,
% and we'll compile it for you on the right. If you open the
% 'Share' menu, you can invite other users to edit at the same
% time. See www.overleaf.com/learn for more info. Enjoy!
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% Inbuilt themes in beamer
\documentclass{beamer}

% Theme choice:
\usetheme{CambridgeUS}

% Title page details: 
\title{Assignment 9} 
\author{Pradeep Mundlik (AI21BTECH11022)}
\date{\today}
% \logo{\large \LaTeX{}}


\begin{document}

% Title page frame
\begin{frame}
    \titlepage 
\end{frame}

% Remove logo from the next slides
% \logo{}


% Outline frame
\begin{frame}{Outline}
    \tableofcontents
\end{frame}


% Lists frame
\section{Question}
\begin{frame}{Question}
    \begin{block}{Papoulis 7.26}
        Using the Cauchy criterion, show that a sequence $x_n$ tends to a limit in the MS sense iff the limit of $E(x_n,x_m)$ as $n,m\rightarrow \infty$ exists.
    \end{block}
\end{frame}

\section{Solution}
\begin{frame}{Solution}
    If $E\{x_n,x_m\} \rightarrow  a $ as $n,m \rightarrow  \infty$, then, given $\epsilon>0$, we can find a number $n_0$ such that, if $n,m > 0$
    \begin{align}
        E\{x_n,x_m\} = a + \theta(n,m) \dots (|\theta| < \epsilon)
    \end{align}
    Hence,
    \begin{align}
        E\{(x_n - x_m)^2\} = &E\{x_n ^2\} + E\{x_m ^2\} - 2E\{x_nx_m\} \\
         = &a + \theta_1 + a + \theta_2 - 2(a + \theta_3) \\
         = &\theta_1 + \theta_2 - 2\theta_3
    \end{align}
    and since it $|\theta_1 + \theta_2 - 2\theta_3| < 4\epsilon$ for any $\epsilon$, it follows that $E\{(x_n - x_m)^2\}\rightarrow 0$, hence (Cauchy) $x_n$ tends to a limit.
\end{frame}
\begin{frame}
    Conversly, \\
    If $x_n \rightarrow x$ in the MS sense, then $E\{(x_n - x)^2\} \rightarrow 0$. \\
    Furthermore, 
    \begin{align}
        E\{x_n ^2\} \rightarrow E\{x^2\} \\
        E\{xx_n\} \rightarrow E\{x^2\} \\
        E^2\{x_n ^2 - x^2\} &= E^2 \{(x_n - x)(x_n + x)\} \\
         &\leq E\{(x_n - x)^2\}E\{(x_n + x)^2\} \rightarrow 0 \\
         E^2\{x(x_n -x)\} \leq E\{x^2\}E{(x_n - x)^2} \rightarrow 0
    \end{align}
\end{frame}
\begin{frame}
    Similarly, 
    \begin{align}
        E^\{(x_n - x)(x_m - x)\} \rightarrow 0
    \end{align}
    Hence,
    \begin{align}
        E\{x_nx_m\} + E\{x^2\} - E{xx_n} - E{xx_m} \rightarrow 0 
    \end{align}
    Combining, we connclude that $E\{x_nx_m\} \rightarrow E\{x^2\}$.
\end{frame}
\end{document}